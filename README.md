# Multimodal Lung Cancer Detection â€” Multi-Agent AI System

A production-grade multi-modal cancer diagnosis pipeline using CT scans, X-ray images, audio signals, and clinical metadata.

## Core Concept & Value

Early lung cancer diagnosis saves lives, but traditional diagnosis depends on:

- CT scan interpretation
- Symptom-based history
- Radiologist experience
- Long wait times
- High expertise requirement

Our system uses a multi-modal AI diagnostic pipeline combining:

- CT / DICOM / NIfTI
- X-Ray / PNG / JPG classifier
- Audio signals (breathing/speech patterns)
- Clinical metadata (age, smoking, symptoms)
- Fusion AI model

This produces:

- A unified cancer score
- Type prediction (Adenocarcinoma, Squamous, Large Cell, Small Cell)
- Nodule detection (CT)
- Confidence heatmaps
- Risk explanation

## The Pitch

### Problem

Lung cancer is often detected too late. Traditional diagnosis suffers from:

- Shortage of radiologists
- Manual, slow CT scan evaluation
- Fragmented data (CT, symptoms, audio)
- High rate of missed nodules
- No unified scoring

### Solution

A multi-agent AI platform that automatically processes:

- CT scan
- Image / X-ray
- Audio diagnosis
- Metadata reasoning
- AI fusion engine

### Value

- Faster diagnosis
- Reduces radiologist workload
- Gives consistent high-accuracy predictions
- Fully automated cloud pipeline
- Works with multiple modalities (CT, audio, image)
- Pause/resume long-running operations
- Agent-based scalable architecture

## System Overview

The system uses a Multi-Agent Architecture, including:

### Sequential Agents

Each modality is processed step-by-step:

- CT Agent
- Image Agent
- Audio Agent
- Metadata Agent
- Fusion Agent

### Parallel Agents

CT and Image models can run simultaneously.

### Loop Agents

Worker continuously polls Redis queue (loop agent).

### Tools Used

| Tool                  | Used?     | Purpose                          |
|-----------------------|-----------|----------------------------------|
| LLM-powered Agent     | âŒ (planned) | Will generate reports & explanations |
| Parallel Agents       | âœ” Yes     | CT/Image can run in parallel     |
| Sequential Agents     | âœ” Yes     | Fusion depends on upstream results |
| Loop Agents           | âœ” Yes     | Worker job polling               |
| MCP                   | âŒ (future) | For future tool orchestration    |
| Custom Tools          | âœ” Yes     | Storage (MinIO), Redis, Docker services |
| Built-in Tools        | âœ” Yes     | Code execution, HTTP requests    |

## File Structure

```
multimodal-lung-cancer-detection-ai/
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ worker/
â”‚   â”‚   â”œâ”€â”€ tasks.py
â”‚   â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”‚   â””â”€â”€ agent_controller.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_service_ct/
â”‚   â”‚   â”œâ”€â”€ service/predict_ct.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_service_audio/
â”‚   â”‚   â”œâ”€â”€ service/predict_audio.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_service_metadata/
â”‚   â”‚   â”œâ”€â”€ service/predict_meta.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_service_image/
â”‚   â”‚   â”œâ”€â”€ service/train.py
â”‚   â”‚   â”œâ”€â”€ service/infer.py
â”‚   â”‚   â”œâ”€â”€ service/models.py
â”‚   â”‚   â”œâ”€â”€ service/utils.py
â”‚   â”‚   â””â”€â”€ service/server.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_service_fusion/
â”‚   â”‚   â”œâ”€â”€ service/predict_fusion.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

## Architecture

```
User Upload â†’ API â†’ Redis Queue â†’ Worker â†’ Agent Controller
          â†“                   â†“
     MinIO Storage â† CT / Image / Audio Files

Agent Controller â†’ CT Model Service
                  â†’ Image Model Service
                  â†’ Audio Service
                  â†’ Metadata Service
                  â†’ Fusion Engine

Fusion Output â†’ API â†’ Frontend UI
```

## Technical Implementation

### Backend

- FastAPI
- Redis (state + queue)
- MinIO (storage)
- PostgreSQL (user jobs)
- Docker Microservices
- Python Agent Controller

### AI Models

- CT Model â†’ Lung nodule detection (dummy now, can be upgraded)
- Image Model â†’ ResNet50 classifier (trained using your dataset)
- Audio Model â†’ Future: CNN/RNN
- Metadata Model â†’ Rule-based (can be upgraded)
- Fusion Model â†’ Normalized averaged probabilities

### Worker

- Loop-based agent
- Processes job queue
- Pause/Resume supported through Redis

### Observability

- Loguru logs
- worker.log
- Docker logs
- Request/Response trace

## OpenAPI Tools

All microservices expose:

- `/predict` (POST)

Auto-documented using FastAPI Swagger:

`http://localhost:<port>/docs`

## Long-Running Operations

Pause / Resume Supported

Each job stores:

- `status = queued | running | paused | completed | failed`
- `progress = 0.0 â†’ 100.0`

Worker checks before processing:

```python
if status == "paused":
    requeue
```

## Sessions & Memory

InMemorySessionService

Stores temporary job states in Redis.

### Future: Memory Bank

LLM agent can store long-term clinical interpretation.

### Context Engineering

Metadata is compacted before passing to fusion model.

## Observability

- Logging: Loguru logs in `/app/logs/worker.log`
- Tracing: Job ID propagated through all agents
- Metrics: (Pending) Prometheus exporters

## Agent Evaluation

You can evaluate each agent independently:

- CT â†’ nodules + probabilities
- Image â†’ classification accuracy
- Audio â†’ anomaly scoring
- Metadata â†’ rule-based correctness
- Fusion â†’ weighted probability consistency

## A2A Protocol (Agent-to-Agent)

Communication between agents uses HTTP JSON RPC style:

- CT Agent â†’ Fusion Agent
- Image Agent â†’ Fusion Agent
- Audio Agent â†’ Fusion Agent
- Metadata Agent â†’ Fusion Agent

## Deployment

### Local

```bash
docker compose build --no-cache
docker compose up
```

### Production Options

- Kubernetes
- Azure Container Apps
- AWS ECS
- Docker Swarm

## Pending Work

| Feature                                      | Status    |
|----------------------------------------------|-----------|
| Replace dummy CT model with real nodule detector | â³ Pending |
| Replace audio dummy model                    | â³ Pending |
| Add LLM-powered radiology report generator   | â³ Planned |
| Heatmap visualisation (Grad-CAM)             | â³ Pending |
| Full UI dashboard                            | â³ Pending |
| Authentication + sessions                    | â³ Pending |
| Add A2A LLM-based decision agent             | â³ Planned |
| Add monitoring dashboards                    | â³ Planned |

## Final Note

Your system is now a multi-agent, multi-modal cancer detection platform with:

- Real trained X-ray model
- Multi-service architecture
- CT / Audio / Metadata / Fusion
- Worker queue
- API + Agent Controller
- Docker microservices
- Storage + Redis + Logging

---

## ğŸ‘©â€ğŸ’» Author

**Poorvi Shetty**
ğŸ’¡ Computer Science Student
ğŸ“˜ Full Stack + Machine Learning Developer

---

## ğŸ“ License

This project is released under the **MIT License**.
You are free to use, modify, and distribute it for learning or research purposes.

---

### â­ If you like this project, give it a star on GitHub! â­
