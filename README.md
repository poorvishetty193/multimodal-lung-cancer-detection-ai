# Multimodal Lung Cancer Detection AI  
### CT Scans â€¢ Cough & Breath Audio â€¢ Metadata â€¢ Multi-Agent System â€¢ Google Gemini

![License](https://img.shields.io/badge/License-MIT-blue.svg)

This project is a **next-generation multimodal AI system** for early **lung cancer risk detection**.  
It integrates **CT scan analysis**, **cough & breath audio classification**, and **patient metadata** using a **multi-agent architecture**.  
The system also includes a **Google Geminiâ€“powered Report Agent** that generates structured, clinical-style radiology reports.

> âš  **Educational & Research Use Only â€” Not a Medical Device**

---

# ğŸš€ Features

### ğŸ§  Multimodal AI
- 3D CT scan preprocessing, lung segmentation & nodule detection  
- Cough & breath audio anomaly classification (CRNN model)  
- Metadata-based risk modeling (age, smoking history, symptoms)  
- Fusion model that combines all signals for final cancer-risk scoring  

### ğŸ¤– Multi-Agent System
- **CT-Agent** â†’ handles CT model inference  
- **Audio-Agent** â†’ processes cough/breath sound  
- **Metadata-Agent** â†’ interprets patient metadata  
- **Fusion-Agent** â†’ combines all embeddings + outputs risk score  
- **Report-Agent** â†’ uses *Google Gemini* to generate clinical-style reports  

### ğŸ”§ Advanced Architecture
- Tools: Gemini API, search grounding (optional), code execution, memory bank  
- Sessions & long-term memory  
- Context compaction for LLM efficiency  
- Observability (logging, metrics, tracing)  
- A2A protocol (agent-to-agent communication)  
- Evaluation pipelines for each model  

### ğŸŒ Full-Stack Application  
- **Frontend:** React (CT uploader + audio recorder + dashboard)  
- **Backend:** FastAPI (manages agents, sessions, ML-service requests)  
- **ML-Service:** Python microservice that runs all ML pipelines  
- **Deployment:** Docker, docker-compose, optional Kubernetes  

---

# ğŸ§¬ System Architecture

sql

             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚    FRONTEND      â”‚
             â”‚  React Web App   â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ API Calls
                       â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚     FASTAPI BACKEND    â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ A2A Messages
                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              MULTI-AGENT SYSTEM           â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚ CT-Agent       Audio-Agent      Metadata-Agent â”‚
    â”‚ Fusion-Agent   Gemini Report-Agent            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚    ML-SERVICE     â”‚
               â”‚ CT | Audio | Fusion Models â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
---

## ğŸ“ Folder Structure

```
cancer-detection-multimodal/
â”‚
â”œâ”€â”€ ml-service/
â”‚   â”œâ”€â”€ ct_pipeline/
â”‚   â”œâ”€â”€ audio_pipeline/
â”‚   â”œâ”€â”€ metadata_pipeline/
â”‚   â”œâ”€â”€ fusion_model/
â”‚   â”œâ”€â”€ report_generator/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ main_inference.py
â”‚
â”œâ”€â”€ multi-agent-system/
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ state/
â”‚   â”œâ”€â”€ observability/
â”‚   â””â”€â”€ a2a_protocol/
â”‚
â”œâ”€â”€ backend/       # FastAPI
â”œâ”€â”€ frontend/      # React
â”œâ”€â”€ evaluation/
â””â”€â”€ deployment/
```


---

# ğŸ›  Tech Stack

### **Machine Learning**
- PyTorch  
- MONAI (medical imaging)  
- librosa / torchaudio  
- Scikit-learn  

### **LLM Tools**
- **Google Gemini API** (report generation + reasoning)
- Search grounding (optional)
- Custom memory bank  
- Context compaction  

### **Backend**
- FastAPI  
- Pydantic  
- Python A2A protocol  
- Observability stack (logs, metrics)

### **Frontend**
- React  
- TailwindCSS  
- Axios  
- Audio recorder API  

### **Deployment**
- Docker / Docker Compose  
- Optional: Kubernetes, GCP free-tier  

---

# ğŸ”Œ Google Gemini Integration

The **Report-Agent** uses Gemini to generate:
- Radiology-style CT findings  
- Audio abnormality summary  
- Combined assessment  
- Recommendations  

Example prompt:

Given the following multimodal results:
CT summary: {ct_summary}
Audio analysis: {audio_summary}
Metadata: {metadata}
Fusion risk score: {risk}

Generate a clinical-style radiology report
with findings, impression, and recommendations.


---

# ğŸ§ª Running the Project

### 1. ML-Service Setup
cd ml-service
pip install -r requirements.txt
python main_inference.py


### 2. Backend
cd backend
uvicorn app.main:app --reload


### 3. Frontend
cd frontend
npm install
npm run dev


### 4. Docker (optional)
docker-compose up --build


---

# ğŸ” Evaluation
Evaluation notebooks are in:

/evaluation/

ct_evaluation.ipynb

audio_evaluation.ipynb

fusion_evaluation.ipynb

agent_evaluation_plan.md


Metrics include:
- CT Dice, F1  
- Audio AUC, recall  
- Fusion AUC, calibration  
- System-level agent evaluation  

---

# ğŸ§· License

This project is released under the **MIT License**.  
See **LICENSE** file for details.

---

# âš  Disclaimer

This system is built **only for educational and research purposes**.  
It is **not** certified for clinical or diagnostic use.

---

# ğŸ™Œ Contributing
Pull requests, feature suggestions, and improvements are welcome!

---

# ğŸ“© Contact
For collaborations or questions, create an issue or reach out via GitHub.
